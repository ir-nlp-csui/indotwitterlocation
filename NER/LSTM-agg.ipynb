{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "171bdaac",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be85059a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:28.896516Z",
     "start_time": "2022-03-24T02:22:27.569794Z"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40192038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:38.626943Z",
     "start_time": "2022-03-24T02:22:37.748476Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device_idx = \"cuda:3\"\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b32a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:39.637364Z",
     "start_time": "2022-03-24T02:22:39.635072Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install keras -q\n",
    "# !pip install tensorflow -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8a1897",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:42.109084Z",
     "start_time": "2022-03-24T02:22:39.994356Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# preliminaries \n",
    "import torchtext\n",
    "from torchtext.legacy.data import Field, LabelField, TabularDataset, BucketIterator\n",
    "# models\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import torch.nn.functional as F\n",
    "# training\n",
    "import torch.optim as optim\n",
    "# reproducible\n",
    "SEED = 42\n",
    "#Torch\n",
    "torch.manual_seed(SEED)\n",
    "#algoritma cuda\n",
    "torch.backends.cudnn.deterministic = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b052c3",
   "metadata": {},
   "source": [
    "## Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72f233d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:44.391314Z",
     "start_time": "2022-03-24T02:22:44.388756Z"
    }
   },
   "outputs": [],
   "source": [
    "userPath = 'original_data/'\n",
    "tweetPath = 'DataWithNERConcat/tweetAgg/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3cc86c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:48.961648Z",
     "start_time": "2022-03-24T02:22:48.843264Z"
    }
   },
   "outputs": [],
   "source": [
    "userlvltrain = pd.read_csv(userPath+'/userlvltrain.csv')\n",
    "userlvltest = pd.read_csv(userPath+'/userlvltest.csv')\n",
    "userlvlval = pd.read_csv(userPath+'/userlvlval.csv')\n",
    "\n",
    "tweets_xtrain_df = pd.read_csv(tweetPath+'aggtrain_df.csv')\n",
    "tweets_xtrain_df.rename(columns={'entityTweetsConcat':'text'}, inplace=True)\n",
    "tweets_xtrain_df['label'] = userlvltrain.Lvalue\n",
    "\n",
    "tweets_xtest_df = pd.read_csv(tweetPath+'aggtest_df.csv')\n",
    "tweets_xtest_df.rename(columns={'entityTweetsConcat':'text'}, inplace=True)\n",
    "tweets_xtest_df['label'] = userlvltest.Lvalue\n",
    "\n",
    "tweets_xval_df = pd.read_csv(tweetPath+'aggval_df.csv')\n",
    "tweets_xval_df.rename(columns={'entityTweetsConcat':'text'}, inplace=True)\n",
    "tweets_xval_df['label'] = userlvltest.Lvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0536661b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:55.858508Z",
     "start_time": "2022-03-24T02:22:54.926054Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(oov_token=True)\n",
    "tokenizer.fit_on_texts(tweets_xtrain_df.text)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# The maximum number of words to be used. \n",
    "vocab_size = len(word_index) + 1 \n",
    "# Max number of words in each tweets.  \n",
    "maxlen = int(tweets_xtrain_df.text.str.len().max()) \n",
    "# This is fixed.\n",
    "embedding_size = 512\n",
    "batch_size = 64\n",
    "\n",
    "print(vocab_size, \"vocab size\")\n",
    "print(maxlen, \"max len\")\n",
    "print(embedding_size, \"embedding dim\")\n",
    "print(batch_size, \"batch size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32763c5b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:22:57.141289Z",
     "start_time": "2022-03-24T02:22:56.929438Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train = tweets_xtrain_df.label\n",
    "Y_test = tweets_xtest_df.label\n",
    "Y_valid = tweets_xval_df.label\n",
    "\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(userlvltrain.userLocation)\n",
    "label_names = le.classes_\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c484aa70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:23:05.001257Z",
     "start_time": "2022-03-24T02:22:59.394352Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer and padding\n",
    "X_train = tokenizer.texts_to_sequences(tweets_xtrain_df.text.values)\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = tokenizer.texts_to_sequences(tweets_xtest_df.text.values) \n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "X_valid = tokenizer.texts_to_sequences(tweets_xval_df.text.values) \n",
    "X_valid = pad_sequences(X_valid, maxlen=maxlen)\n",
    "\n",
    "# Load train and test in CUDA Memory\n",
    "x_train = torch.tensor(X_train, dtype=torch.long).cuda()\n",
    "y_train = torch.tensor(Y_train, dtype=torch.long).cuda()\n",
    "x_test = torch.tensor(X_test, dtype=torch.long).cuda() \n",
    "y_test = torch.tensor(Y_test, dtype=torch.long).cuda()\n",
    "x_valid = torch.tensor(X_valid, dtype=torch.long).cuda()\n",
    "y_valid = torch.tensor(Y_valid, dtype=torch.long).cuda()\n",
    "\n",
    "# Create Torch datasets\n",
    "train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "valid = torch.utils.data.TensorDataset(x_valid, y_valid)\n",
    "\n",
    "\n",
    "# Create Data Loaders\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "valid_loader = torch.utils.data.DataLoader(valid, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f79b32",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce239f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:23:06.105964Z",
     "start_time": "2022-03-24T02:23:06.099875Z"
    }
   },
   "outputs": [],
   "source": [
    "class BiLSTM(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(BiLSTM, self).__init__()\n",
    "        self.hidden_size = 1\n",
    "        drp = 0.5\n",
    "        n_classes = len(le.classes_)\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.lstm = nn.LSTM(embedding_size, self.hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear = nn.Linear(self.hidden_size*4 , 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(drp)\n",
    "        self.out = nn.Linear(1, n_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #rint(x.size())\n",
    "        h_embedding = self.embedding(x)\n",
    "        #_embedding = torch.squeeze(torch.unsqueeze(h_embedding, 0))\n",
    "        h_lstm, _ = self.lstm(h_embedding)\n",
    "        avg_pool = torch.mean(h_lstm, 1)\n",
    "        max_pool, _ = torch.max(h_lstm, 1)\n",
    "        conc = torch.cat(( avg_pool, max_pool), 1)\n",
    "        conc = self.relu(self.linear(conc))\n",
    "        conc = self.dropout(conc)\n",
    "        out = self.out(conc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb92b15",
   "metadata": {},
   "source": [
    "### LSTM training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424d4b0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-24T02:23:09.056047Z",
     "start_time": "2022-03-24T02:23:07.331224Z"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 30\n",
    "n_epochs_stop = 3 \n",
    "epochs_no_improve = 0\n",
    "early_stop = False\n",
    "min_val_loss = np.Inf\n",
    "\n",
    "\n",
    "lstm = BiLSTM()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, lstm.parameters()), lr=5e-3)\n",
    "lstm.cuda()\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time.time()\n",
    "    # Set model to train configuration\n",
    "    lstm.train()\n",
    "    avg_loss = 0.  \n",
    "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "        # Predict/Forward Pass\n",
    "        y_pred = lstm(x_batch)\n",
    "        # Compute loss\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "\n",
    "        if avg_loss < min_val_loss:\n",
    "          epochs_no_improve = 0\n",
    "          min_val_loss = avg_loss\n",
    "        else:\n",
    "          epochs_no_improve += 1 \n",
    "        \n",
    "        if epoch>3 and epochs_no_improve == n_epochs_stop:\n",
    "            print('Early stopping!' )\n",
    "            early_stop = True\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "    if early_stop:\n",
    "      break\n",
    "  \n",
    "    # Set model to validation configuration -Doesn't get trained here\n",
    "    lstm.eval()        \n",
    "    avg_val_loss = 0.\n",
    "    val_preds = np.zeros((len(x_valid),len(le.classes_)))\n",
    "    \n",
    "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "        y_pred = lstm(x_batch).detach()\n",
    "        avg_val_loss += loss_fn(y_pred, y_batch).item() / len(valid_loader)\n",
    "        # keep/store predictions\n",
    "        val_preds[i * batch_size:(i+1) * batch_size] = F.softmax(y_pred, dim = 1).cpu().numpy()\n",
    "    \n",
    "    # Check Accuracy\n",
    "    val_accuracy = sum(val_preds.argmax(axis=1)==Y_valid)/len(Y_valid)\n",
    "    train_loss.append(avg_loss)\n",
    "    valid_loss.append(avg_val_loss)\n",
    "    elapsed_time = time.time() - start_time \n",
    "    print('Epoch {}/{} \\t loss={:.4f} \\t val_loss={:.4f}  \\t val_acc={:.4f}  \\t time={:.2f}s'.format(\n",
    "                epoch + 1, n_epochs, avg_loss, avg_val_loss, val_accuracy, elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7a08db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T08:49:27.513547Z",
     "start_time": "2022-03-12T08:49:27.290034Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graph(epochs):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    plt.title(\"Train/Validation Loss\")\n",
    "    plt.plot(list(np.arange(epochs) + 1) , train_loss, label='train')\n",
    "    plt.plot(list(np.arange(epochs) + 1), valid_loss, label='validation')\n",
    "    plt.xlabel('num_epochs', fontsize=12)\n",
    "    plt.ylabel('loss', fontsize=12)\n",
    "    plt.legend(loc='best')\n",
    "plot_graph(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255c435b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T08:49:37.588392Z",
     "start_time": "2022-03-12T08:49:37.135919Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(lstm.state_dict(), 'lstm_agg.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2c0bac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T08:49:39.322908Z",
     "start_time": "2022-03-12T08:49:38.735092Z"
    }
   },
   "outputs": [],
   "source": [
    "saved_model = BiLSTM()\n",
    "saved_model.load_state_dict(torch.load('lstm_agg.pt'))\n",
    "saved_model.eval()\n",
    "saved_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e4414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T08:49:41.599281Z",
     "start_time": "2022-03-12T08:49:40.156005Z"
    }
   },
   "outputs": [],
   "source": [
    "#  Fungsi evaluasi\n",
    "def predict(model, test_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "      test_preds = np.zeros((len(x_test),len(le.classes_)))\n",
    "      for i, (x_batch, y_batch) in enumerate(test_loader):\n",
    "        y_pred = model(x_batch).detach()\n",
    "        # keep/store predictions\n",
    "        test_preds[i * batch_size:(i+1) * batch_size] = F.softmax(y_pred, dim = 1).cpu().numpy()\n",
    "      test_preds = test_preds.argmax(axis=1)\n",
    "      return test_preds\n",
    "\n",
    "ypred = predict(saved_model, test_loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de219628",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-12T08:49:51.009228Z",
     "start_time": "2022-03-12T08:49:51.000020Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('accuracy %s' % round(accuracy_score(Y_test, ypred),2 ))\n",
    "print(classification_report(Y_test, ypred,target_names=label_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

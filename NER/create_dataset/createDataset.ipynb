{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609e7ef4",
   "metadata": {},
   "source": [
    "## Library import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "19ed34b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:21:08.179837Z",
     "start_time": "2022-03-23T06:21:08.175379Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import json, glob, os, random\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import re\n",
    "import emoji\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f3a8c",
   "metadata": {},
   "source": [
    "## pretrained NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc124e90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:21:11.365147Z",
     "start_time": "2022-03-23T06:21:09.472713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Mar 23 06:21:10 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.126.02   Driver Version: 418.126.02   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   34C    P0    57W / 300W |  19642MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    71W / 300W |  13700MiB / 32480MiB |     31%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   108W / 300W |  14346MiB / 32480MiB |     30%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   64C    P0   263W / 300W |  13400MiB / 32480MiB |    100%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   37C    P0    58W / 300W |  15746MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   39C    P0    58W / 300W |  31598MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   56C    P0   255W / 300W |  31894MiB / 32480MiB |     62%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   33C    P0    55W / 300W |  15597MiB / 32480MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d70012c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:21:27.080121Z",
     "start_time": "2022-03-23T06:21:27.075330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "torch.cuda.set_device(3)\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "device_idx = \"cuda:3\"\n",
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ca0fbfb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:21:28.140996Z",
     "start_time": "2022-03-23T06:21:28.138369Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718cd8ac",
   "metadata": {},
   "source": [
    "### Helper Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63d17054",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:21:38.127525Z",
     "start_time": "2022-03-23T06:21:30.171017Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# fold here\n",
    "import json, glob, os, random\n",
    "import argparse\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel, BertConfig\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import re\n",
    "import emoji\n",
    "from seqeval.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import sys\n",
    "sys.argv=['']\n",
    "del sys\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "model_dict = { 'indobertweet': 'indolem/indobertweet-base-uncased',\n",
    "               'indobert': 'indolem/indobert-base-uncased'}\n",
    "\n",
    "\n",
    "def find_url(string):\n",
    "    # with valid conditions for urls in string \n",
    "    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "    url = re.findall(regex,string)\n",
    "    return [x[0] for x in url]\n",
    "\n",
    "def preprocess_tweet(tweet):\n",
    "    #print(tweet)\n",
    "    tweet = emoji.demojize(tweet).lower()\n",
    "    new_tweet = []\n",
    "    for word in tweet.split():\n",
    "        if word[0] == '@':\n",
    "            new_tweet.append('@USER')\n",
    "        elif find_url(word) != []:\n",
    "            new_tweet.append('HTTPURL')\n",
    "        elif word == 'httpurl':\n",
    "            new_tweet.append('HTTPURL')\n",
    "        else:\n",
    "            new_tweet.append(word)\n",
    "    return ' '.join(new_tweet)\n",
    "\n",
    "def set_seed(args):\n",
    "    random.seed(args.seed)\n",
    "    np.random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    if args.n_gpu > 0:\n",
    "        torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "\n",
    "class BertData():\n",
    "    def __init__(self, args):\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(model_dict[args.bert_model], do_lower_case=True)\n",
    "        self.sep_token = '[SEP]'\n",
    "        self.cls_token = '[CLS]'\n",
    "        self.pad_token = '[PAD]'\n",
    "        self.sep_vid = self.tokenizer.vocab[self.sep_token]\n",
    "        self.cls_vid = self.tokenizer.vocab[self.cls_token]\n",
    "        self.pad_vid = self.tokenizer.vocab[self.pad_token]\n",
    "        self.MAX_TOKEN = args.max_token\n",
    "        self.args = args\n",
    "\n",
    "    def preprocess_one(self, src_txt, label):\n",
    "        new_src = []\n",
    "        new_label = []\n",
    "        \n",
    "        for idx, word in enumerate(src_txt):\n",
    "            s = []; l = []\n",
    "            for subword in self.tokenizer.tokenize(word):\n",
    "                s.append(subword)\n",
    "                l.append(args.vocab_label_size)\n",
    "            l[0] = label[idx]\n",
    "            new_src += s\n",
    "            new_label += l\n",
    "\n",
    "        src_subtokens = [self.cls_token] + new_src + [self.sep_token]\n",
    "        new_label = [args.vocab_label_size] + new_label + [args.vocab_label_size]\n",
    "        src_subtoken_idxs = self.tokenizer.convert_tokens_to_ids(src_subtokens)\n",
    "        if len(src_subtoken_idxs) > self.MAX_TOKEN:\n",
    "            src_subtoken_idxs = src_subtoken_idxs[:self.MAX_TOKEN]\n",
    "            src_subtoken_idxs[-1] = self.sep_vid\n",
    "            new_label = new_label[:self.MAX_TOKEN]\n",
    "        else:\n",
    "            len_to_add = self.MAX_TOKEN-len(src_subtoken_idxs)\n",
    "            src_subtoken_idxs += [self.pad_vid] * (len_to_add)\n",
    "            new_label += [self.args.vocab_label_size] * (len_to_add)\n",
    "        \n",
    "        segments_ids = [0] * len(src_subtoken_idxs)\n",
    "        assert len(src_subtoken_idxs) == len(segments_ids) == len(new_label)\n",
    "        return src_subtoken_idxs, segments_ids, new_label\n",
    "    \n",
    "    def preprocess(self, src_txts, labels):\n",
    "        assert len(src_txts) == len(labels)\n",
    "        output = []\n",
    "        for idx in range(len(src_txts)):\n",
    "            output.append(self.preprocess_one(src_txts[idx], labels[idx]))\n",
    "        return output\n",
    "\n",
    "\n",
    "class Batch():\n",
    "    def __init__(self, data, idx, batch_size, device):\n",
    "        cur_batch = data[idx:idx+batch_size] \n",
    "        src = torch.tensor([x[0] for x in cur_batch])\n",
    "        seg = torch.tensor([x[1] for x in cur_batch])\n",
    "        label = torch.tensor([x[2] for x in cur_batch])\n",
    "        mask_src = 0 + (src != 0)\n",
    "        \n",
    "        self.src = src.to(device)\n",
    "        self.seg= seg.to(device)\n",
    "        self.label = label.to(device)\n",
    "        self.mask_src = mask_src.to(device)\n",
    "\n",
    "    def get(self):\n",
    "        return self.src, self.seg, self.label, self.mask_src\n",
    "\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, args, device):\n",
    "        super(Model, self).__init__()\n",
    "        self.args = args\n",
    "        self.device = device\n",
    "        self.bert = BertModel.from_pretrained(model_dict[args.bert_model], return_dict=False)\n",
    "        self.linear = nn.Linear(self.bert.config.hidden_size, args.vocab_label_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.loss = torch.nn.CrossEntropyLoss(ignore_index=args.vocab_label_size, reduction='sum')\n",
    "\n",
    "    def forward(self, src, seg, mask_src):\n",
    "        top_vec, _ = self.bert(input_ids=src, token_type_ids=seg, attention_mask=mask_src)\n",
    "        top_vec = self.dropout(top_vec)\n",
    "        top_vec *= mask_src.unsqueeze(dim=-1).float()\n",
    "        conclusion = self.linear(top_vec).squeeze()\n",
    "        return conclusion\n",
    "    \n",
    "    def get_loss(self, src, seg, label, mask_src):\n",
    "        output = self.forward(src, seg, mask_src)\n",
    "        return self.loss(output.view(-1,self.args.vocab_label_size), label.view(-1))\n",
    "\n",
    "    def predict(self, src, seg, mask_src):\n",
    "        output = self.forward(src, seg, mask_src)\n",
    "        batch_size = output.shape[0]\n",
    "        prediction = torch.argmax(output.view(batch_size, -1, args.vocab_label_size), dim=-1).data.cpu().numpy().tolist()\n",
    "        return prediction\n",
    "\n",
    "\n",
    "def align (preds, golds, args):\n",
    "    new_golds = []; new_preds = []\n",
    "    for idx, gold in enumerate(golds):\n",
    "        new_gold = []; new_pred = []\n",
    "        for idy in range(len(gold)):\n",
    "            if gold[idy] == args.vocab_label_size:\n",
    "                continue\n",
    "            else:\n",
    "                new_gold.append(args.id2label[gold[idy]])\n",
    "                new_pred.append(args.id2label[preds[idx][idy]])\n",
    "        new_golds.append(new_gold)\n",
    "        new_preds.append(new_pred)\n",
    "    return new_preds, new_golds\n",
    "\n",
    "def prediction(dataset, model, args):\n",
    "    preds = []\n",
    "    golds = []\n",
    "    model.eval()\n",
    "    for j in range(0, len(dataset), args.batch_size):\n",
    "        src, seg, label, mask_src = Batch(dataset, j, args.batch_size, args.device).get()\n",
    "        preds += model.predict(src, seg, mask_src)\n",
    "        golds += label.cpu().data.numpy().tolist()\n",
    "    preds = np.array(preds)\n",
    "    golds = np.array(golds)\n",
    "    preds, golds = align (preds, golds, args)\n",
    "    return f1_score(golds, preds), preds\n",
    "\n",
    "def train(args, train_dataset, dev_dataset, test_formal_dataset, test_informal_dataset, model, id2label):\n",
    "    \"\"\" Train the model \"\"\"\n",
    "    # Prepare optimizer and schedule (linear warmup and decay)\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    t_total = len(train_dataset) // args.batch_size * args.num_train_epochs\n",
    "    args.warmup_steps = int(0.1 * t_total)\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
    "    ]\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
    "    )\n",
    "\n",
    "    # Train!\n",
    "    logger.info(\"***** Running training *****\")\n",
    "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
    "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
    "    logger.info(\"  Warming up = %d\", args.warmup_steps)\n",
    "    logger.info(\"  Patience  = %d\", args.patience)\n",
    "\n",
    "    # Added here for reproductibility\n",
    "    set_seed(args)\n",
    "    tr_loss = 0.0\n",
    "    global_step = 1\n",
    "    best_f1_dev = 0; test_formal_f1 = 0; test_informal_f1 = 0\n",
    "    cur_patience = 0\n",
    "    for i in tqdm(range(int(args.num_train_epochs))):\n",
    "        random.shuffle(train_dataset)\n",
    "        epoch_loss = 0.0\n",
    "        for j in range(0, len(train_dataset), args.batch_size):\n",
    "            src, seg, label, mask_src = Batch(train_dataset, j, args.batch_size, args.device).get()\n",
    "            model.train()\n",
    "            loss = model.get_loss(src, seg, label, mask_src)\n",
    "            loss = loss.sum()/args.batch_size\n",
    "            if args.n_gpu > 1:\n",
    "                loss = loss.mean()  # mean() to average on multi-gpu parallel (not distributed) training\n",
    "            loss.backward()\n",
    "\n",
    "            tr_loss += loss.item()\n",
    "            epoch_loss += loss.item()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
    "            optimizer.step()\n",
    "            scheduler.step()  # Update learning rate schedule\n",
    "            model.zero_grad()\n",
    "            global_step += 1\n",
    "        logger.info(\"Finish epoch = %s, loss_epoch = %s\", i+1, epoch_loss/global_step)\n",
    "        dev_f1, _ = prediction(dev_dataset, model, args)\n",
    "        if dev_f1 > best_f1_dev:\n",
    "            best_f1_dev = dev_f1\n",
    "            test_formal_f1, _ = prediction(test_formal_dataset, model, args)\n",
    "            test_informal_f1, _ = prediction(test_informal_dataset, model, args)\n",
    "            cur_patience = 0\n",
    "            logger.info(\"Better, BEST F1 in DEV = %s, F1 in FORMAL_TEST = %s, F1 in INFORMAL_TEST = %s\", best_f1_dev, test_formal_f1, test_informal_f1)\n",
    "            torch.save(model.state_dict(), PATH+\"nerbertweet.pt\")\n",
    "        else:\n",
    "            cur_patience += 1\n",
    "            if cur_patience == args.patience:\n",
    "                logger.info(\"Early Stopping Not Better, BEST F1 in DEV = %s, F1 in FORMAL_TEST = %s, F1 in INFORMAL_TEST  = %s\", best_f1_dev, test_formal_f1, test_informal_f1)\n",
    "                torch.save(model.state_dict(), PATH+\"nerbertweet.pt\")\n",
    "                break\n",
    "            else:\n",
    "                logger.info(\"Not Better, BEST F1 in DEV = %s, F1 in FORMAL_TEST = %s, F1 in INFORMAL_TEST  = %s\", best_f1_dev, test_formal_f1, test_informal_f1)\n",
    "\n",
    "    return global_step, tr_loss / global_step, best_f1_dev\n",
    "\n",
    "\n",
    "args_parser = argparse.ArgumentParser()\n",
    "args_parser.add_argument('--bert_model', default='indobertweet', choices=['indobert', 'indobertweet'], help='select one of models')\n",
    "args_parser.add_argument('--data_path', default='data/', help='path to all train/test/dev')\n",
    "args_parser.add_argument('--max_token', type=int, default=256, help='maximum token allowed for 1 instance')\n",
    "args_parser.add_argument('--batch_size', type=int, default=30, help='batch size')\n",
    "args_parser.add_argument('--learning_rate', type=float, default=5e-5, help='learning rate')\n",
    "args_parser.add_argument('--weight_decay', type=int, default=0, help='weight decay')\n",
    "args_parser.add_argument('--adam_epsilon', type=float, default=1e-8, help='adam epsilon')\n",
    "args_parser.add_argument('--max_grad_norm', type=float, default=1.0)\n",
    "args_parser.add_argument('--num_train_epochs', type=int, default=20, help='total epoch')\n",
    "args_parser.add_argument('--warmup_steps', type=int, default=242, help='warmup_steps, the default value is 10% of total steps')\n",
    "args_parser.add_argument('--logging_steps', type=int, default=200, help='report stats every certain steps')\n",
    "args_parser.add_argument('--seed', type=int, default=2020)\n",
    "args_parser.add_argument('--local_rank', type=int, default=-1)\n",
    "args_parser.add_argument('--patience', type=int, default=5, help='patience for early stopping')\n",
    "args_parser.add_argument('--no_cuda', default=False)\n",
    "args = args_parser.parse_args()\n",
    "\n",
    "\n",
    "# Setup CUDA, GPU & distributed training\n",
    "if args.local_rank == -1 or args.no_cuda:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not args.no_cuda else \"cpu\")\n",
    "    args.n_gpu = torch.cuda.device_count()\n",
    "else: # Initializes the distributed backend which will take care of sychronizing nodes/GPUs\n",
    "    torch.cuda.set_device(args.local_rank)\n",
    "    device = torch.device(\"cuda\", args.local_rank)\n",
    "    torch.distributed.init_process_group(backend=\"nccl\")\n",
    "    args.n_gpu = 1\n",
    "args.device = device\n",
    "\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO if args.local_rank in [-1, 0] else logging.WARN,\n",
    ")\n",
    "\n",
    "set_seed(args)\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "if args.local_rank not in [-1, 0]:\n",
    "    # Make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "if args.local_rank == 0:\n",
    "    # Make sure only the first process in distributed training will download model & vocab\n",
    "    torch.distributed.barrier()\n",
    "\n",
    "# it is not posssible to use BIO format because of the annotation procedure\n",
    "# however, we add tag B in the front, for using seqeval\n",
    "def standardize(tag):\n",
    "    if tag in ['PERSON', 'ORGANIZATION', 'LOCATION']:\n",
    "        return 'B-' + tag\n",
    "    return tag\n",
    "\n",
    "def read_data(fname):\n",
    "    lines = [x.strip() for x in open(fname).readlines()]\n",
    "    data = []; label = []\n",
    "    for line in lines:\n",
    "        words = []; tags = []\n",
    "        for pair in line.split(' '):\n",
    "            items = pair.split('/')\n",
    "            words.append(str('/'.join(items[:-1])))\n",
    "            tags.append(standardize(items[-1]))\n",
    "        words = preprocess_tweet(' '.join(words)).split()\n",
    "        data.append(words)\n",
    "        label.append(tags)\n",
    "    return data, label\n",
    "\n",
    "def create_vocab(labels):\n",
    "    new_labels = []\n",
    "    for l in labels:\n",
    "        new_labels += l\n",
    "    unique = np.unique(new_labels)\n",
    "    label2id = {}\n",
    "    id2label = {}\n",
    "    counter = 0\n",
    "    for word in unique:\n",
    "        label2id[word] = counter\n",
    "        id2label[counter] = word\n",
    "        counter += 1\n",
    "    return label2id, id2label\n",
    "\n",
    "def convert_label2id(label2id, labels):\n",
    "    res = []\n",
    "    for label in labels:\n",
    "        res.append([label2id[x] for x in label])\n",
    "    return res\n",
    "\n",
    "\n",
    "xtrain, ytrain = read_data(args.data_path+'train.txt')\n",
    "xdev, ydev = read_data(args.data_path+'dev.txt')\n",
    "xtest_formal, ytest_formal = read_data(args.data_path+'test_formal.txt')\n",
    "xtest_informal, ytest_informal = read_data(args.data_path+'test_informal.txt')\n",
    "\n",
    "label2id, id2label = create_vocab (ytrain)\n",
    "args.vocab_label_size = len(label2id)\n",
    "args.label2id = label2id\n",
    "args.id2label = id2label\n",
    "\n",
    "ytrain =  convert_label2id (label2id, ytrain)\n",
    "ydev =  convert_label2id (label2id, ydev)\n",
    "ytest_formal =  convert_label2id (label2id, ytest_formal)\n",
    "ytest_informal =  convert_label2id (label2id, ytest_informal)\n",
    "\n",
    "bertdata = BertData(args)\n",
    "\n",
    "# train_dataset = bertdata.preprocess(xtrain, ytrain)\n",
    "# dev_dataset = bertdata.preprocess(xdev, ydev)\n",
    "# test_formal_dataset = bertdata.preprocess(xtest_formal, ytest_formal)\n",
    "# test_informal_dataset = bertdata.preprocess(xtest_informal, ytest_informal)\n",
    "    \n",
    "# model = Model(args, device)\n",
    "# model.to(args.device)\n",
    "# global_step, tr_loss, best_f1_dev= train(args, train_dataset, dev_dataset, test_formal_dataset, test_informal_dataset, model, id2label)\n",
    "\n",
    "# print('Dev set F1', best_f1_dev)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c575548f",
   "metadata": {},
   "source": [
    "### pretrained NER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a001cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:21:38.165523Z",
     "start_time": "2022-03-23T06:21:36.891Z"
    }
   },
   "outputs": [],
   "source": [
    "import gdown \n",
    "pretrained_NER_path = 'nerbertweet.pt'\n",
    "if not os.path.exists(pretrained_NER_path):\n",
    "    drive_id = \"1-1JJPOqmQ6ydxv-1vZ_mv911Ftxl71xQ\"\n",
    "    gdown.download(id=drive_id, quiet=False, fuzzy=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921af0f9",
   "metadata": {},
   "source": [
    "## Tweets data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "60c87089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:28:02.529787Z",
     "start_time": "2022-03-23T06:28:02.527078Z"
    }
   },
   "outputs": [],
   "source": [
    "folderPATH ='original_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d3e7451",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:28:03.073286Z",
     "start_time": "2022-03-23T06:28:03.059384Z"
    }
   },
   "outputs": [],
   "source": [
    "userlvltrain = pd.read_csv(folderPATH+'userlvltrain.csv')\n",
    "userlvltest = pd.read_csv(folderPATH+'userlvltest.csv')\n",
    "userlvlval = pd.read_csv(folderPATH+'userlvlval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f948f25b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:28:30.116950Z",
     "start_time": "2022-03-23T06:28:29.558326Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(folderPATH+'train_df.csv')\n",
    "train_df.dropna(subset = [\"text\"], inplace=True)\n",
    "test_df = pd.read_csv(folderPATH+'test_df.csv')\n",
    "test_df.dropna(subset = [\"text\"], inplace=True)\n",
    "val_df = pd.read_csv(folderPATH+'val_df.csv')\n",
    "val_df.dropna(subset = [\"text\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bd585d",
   "metadata": {},
   "source": [
    "## Apply pretrained NER to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "832e5ab3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:28:55.874639Z",
     "start_time": "2022-03-23T06:28:41.333889Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at indolem/indobertweet-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f726d46c760>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myNERmodel = Model(args, device)\n",
    "\n",
    "myNERmodel.to(args.device)\n",
    "\n",
    "myNERmodel.load_state_dict(torch.load(pretrained_NER_path))\n",
    "\n",
    "myNERmodel.eval()\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71c50a73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:28:57.690524Z",
     "start_time": "2022-03-23T06:28:57.684056Z"
    },
    "code_folding": [
     1,
     11,
     22
    ]
   },
   "outputs": [],
   "source": [
    "## return location given NER prediction results for every rows \n",
    "def NER_text_to_location_features(text, NERprediction):\n",
    "  data = []\n",
    "  for foo, bar in zip(text, NERprediction[1]):\n",
    "    d = []\n",
    "    for i in range(len(foo)):\n",
    "      if bar[i] == 'B-LOCATION':\n",
    "        d.append(foo[i])\n",
    "    data.append(d)\n",
    "  return data\n",
    "\n",
    "def NER_text_to_features(text, NERprediction):\n",
    "  data = []\n",
    "  for foo, bar in zip(text, NERprediction[1]):\n",
    "    d = []\n",
    "    for i in range(len(foo)):\n",
    "      if bar[i] == 'B-LOCATION' or bar[i] == 'B-PERSON' or bar[i] == 'B-ORGANIZATION':\n",
    "        d.append(foo[i])\n",
    "    data.append(d)\n",
    "  return data\n",
    "\n",
    "## return X and Y for training NER \n",
    "def create_xy_for_NER(text):\n",
    "  xtrain_text_preprocessed = []; ytrain_text_dummy = []\n",
    "  for t in text:\n",
    "    t = list(map(str, t.split(\" \")))\n",
    "    t = [x for x in t if x]\n",
    "    xtrain_text_preprocessed.append(t)\n",
    "  for data in xtrain_text_preprocessed:\n",
    "    ones = []\n",
    "    for d in data:\n",
    "      ones.append(random.randint(0, 3))\n",
    "    ytrain_text_dummy.append(ones)\n",
    "  return xtrain_text_preprocessed, ytrain_text_dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4610e34a",
   "metadata": {},
   "source": [
    "### only tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9fe5256",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:29:35.396214Z",
     "start_time": "2022-03-23T06:29:32.817925Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain_text_preprocessed, ytrain_text_dummy = create_xy_for_NER(train_df['text'])\n",
    "xtest_text_preprocessed, ytest_text_dummy = create_xy_for_NER(test_df['text']) \n",
    "xval_text_preprocessed, yval_text_dummy = create_xy_for_NER(val_df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1a791a4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:31:57.117897Z",
     "start_time": "2022-03-23T06:29:47.261366Z"
    }
   },
   "outputs": [],
   "source": [
    "train_text_dataset = bertdata.preprocess(xtrain_text_preprocessed, ytrain_text_dummy)\n",
    "test_text_dataset = bertdata.preprocess(xtest_text_preprocessed, ytest_text_dummy)\n",
    "val_text_dataset = bertdata.preprocess(xval_text_preprocessed, yval_text_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "73e91b07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:54:59.774831Z",
     "start_time": "2022-03-23T06:33:14.648611Z"
    }
   },
   "outputs": [],
   "source": [
    "trainNER = prediction(train_text_dataset, myNERmodel, args)\n",
    "testNER = prediction(test_text_dataset, myNERmodel, args)\n",
    "valNER = prediction(val_text_dataset, myNERmodel, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "067d1ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:56:53.231868Z",
     "start_time": "2022-03-23T06:56:52.738313Z"
    }
   },
   "outputs": [],
   "source": [
    "locXtrain = NER_text_to_location_features(xtrain_text_preprocessed, trainNER)\n",
    "locXtest = NER_text_to_location_features(xtest_text_preprocessed, testNER)\n",
    "locXval = NER_text_to_location_features(xval_text_preprocessed, valNER)\n",
    "\n",
    "nerXtrain =  NER_text_to_features(xtrain_text_preprocessed, trainNER)\n",
    "nerXtest = NER_text_to_features(xtest_text_preprocessed, testNER)\n",
    "nerXval = NER_text_to_features(xval_text_preprocessed, valNER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f99d460b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:27:09.404440Z",
     "start_time": "2022-03-23T07:27:09.329334Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['mentionedLocationTweets'] = locXtrain\n",
    "test_df['mentionedLocationTweets'] = locXtest\n",
    "val_df['mentionedLocationTweets'] = locXval\n",
    "\n",
    "train_df['mentionedEntityTweets'] = nerXtrain\n",
    "test_df['mentionedEntityTweets'] = nerXtest\n",
    "val_df['mentionedEntityTweets'] = nerXval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ab8c2b",
   "metadata": {},
   "source": [
    "### only username"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6d323dc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:58:02.631592Z",
     "start_time": "2022-03-23T06:58:02.625163Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_username_str = train_df['display_name'].astype(str)\n",
    "test_df_username_str = test_df['display_name'].astype(str)\n",
    "val_df_username_str = val_df['display_name'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "85417f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:58:05.577955Z",
     "start_time": "2022-03-23T06:58:03.917335Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain_text_preprocessed_username, ytrain_text_dummy_username = create_xy_for_NER(train_df_username_str)\n",
    "xtest_text_preprocessed_username, ytest_text_dummy_username = create_xy_for_NER(test_df_username_str) \n",
    "xval_text_preprocessed_username, yval_text_dummy_username = create_xy_for_NER(val_df_username_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6bf1c32a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T06:58:42.366016Z",
     "start_time": "2022-03-23T06:58:19.288435Z"
    }
   },
   "outputs": [],
   "source": [
    "train_text_dataset_username = bertdata.preprocess(xtrain_text_preprocessed_username, ytrain_text_dummy_username)\n",
    "test_text_dataset_username = bertdata.preprocess(xtest_text_preprocessed_username, ytest_text_dummy_username)\n",
    "val_text_dataset_username = bertdata.preprocess(xval_text_preprocessed_username, yval_text_dummy_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e163bc6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:20:23.743604Z",
     "start_time": "2022-03-23T06:58:51.410464Z"
    }
   },
   "outputs": [],
   "source": [
    "trainNER_username = prediction(train_text_dataset_username, myNERmodel, args)\n",
    "testNER_username = prediction(test_text_dataset_username, myNERmodel, args)\n",
    "valNER_username = prediction(val_text_dataset_username, myNERmodel, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebe7a224",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:21:45.335522Z",
     "start_time": "2022-03-23T07:21:45.143078Z"
    }
   },
   "outputs": [],
   "source": [
    "locXtrain_username = NER_text_to_location_features(xtrain_text_preprocessed_username, trainNER_username)\n",
    "locXtest_username = NER_text_to_location_features(xtest_text_preprocessed_username, testNER_username)\n",
    "locXval_username = NER_text_to_location_features(xval_text_preprocessed_username, valNER_username)\n",
    "\n",
    "nerXtrain_username =  NER_text_to_features(xtrain_text_preprocessed_username, trainNER_username)\n",
    "nerXtest_username = NER_text_to_features(xtest_text_preprocessed_username, testNER_username)\n",
    "nerXval_username = NER_text_to_features(xval_text_preprocessed_username, valNER_username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b51b266",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:27:13.211928Z",
     "start_time": "2022-03-23T07:27:13.142345Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['mentionedLocationDisplayname'] = locXtrain_username\n",
    "test_df['mentionedLocationDisplayname'] = locXtest_username\n",
    "val_df['mentionedLocationDisplayname'] = locXval_username\n",
    "\n",
    "train_df['mentionedEntityDisplayname'] = nerXtrain_username\n",
    "test_df['mentionedEntityDisplayname'] = nerXtest_username\n",
    "val_df['mentionedEntityDisplayname'] = nerXval_username"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c8ef5f",
   "metadata": {},
   "source": [
    "### only description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e3e0504f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:29:59.841667Z",
     "start_time": "2022-03-23T07:29:59.839339Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_df.description = train_df['description'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c76a4fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:29:19.086095Z",
     "start_time": "2022-03-23T07:29:19.077923Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_userdesc_str = train_df['description'].astype(str)\n",
    "test_df_userdesc_str = test_df['description'].astype(str)\n",
    "val_df_userdesc_str = val_df['description'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "40246095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:30:11.024752Z",
     "start_time": "2022-03-23T07:30:07.256958Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain_text_preprocessed_userdesc, ytrain_text_dummy_userdesc = create_xy_for_NER(train_df_userdesc_str)\n",
    "xtest_text_preprocessed_userdesc, ytest_text_dummy_userdesc = create_xy_for_NER(test_df_userdesc_str) \n",
    "xval_text_preprocessed_userdesc, yval_text_dummy_userdesc = create_xy_for_NER(val_df_userdesc_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "bca9e4ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:31:47.566288Z",
     "start_time": "2022-03-23T07:30:13.015361Z"
    }
   },
   "outputs": [],
   "source": [
    "train_text_dataset_userdesc = bertdata.preprocess(xtrain_text_preprocessed_userdesc, ytrain_text_dummy_userdesc)\n",
    "test_text_dataset_userdesc = bertdata.preprocess(xtest_text_preprocessed_userdesc, ytest_text_dummy_userdesc)\n",
    "val_text_dataset_userdesc = bertdata.preprocess(xval_text_preprocessed_userdesc, yval_text_dummy_userdesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "05bcc3b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T07:53:53.783682Z",
     "start_time": "2022-03-23T07:32:12.778412Z"
    }
   },
   "outputs": [],
   "source": [
    "trainNER_userdesc = prediction(train_text_dataset_userdesc, myNERmodel, args)\n",
    "testNER_userdesc = prediction(test_text_dataset_userdesc, myNERmodel, args)\n",
    "valNER_userdesc = prediction(val_text_dataset_userdesc, myNERmodel, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a685e70c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T08:24:38.121189Z",
     "start_time": "2022-03-23T08:24:37.676397Z"
    }
   },
   "outputs": [],
   "source": [
    "locXtrain_userdesc = NER_text_to_location_features(xtrain_text_preprocessed_userdesc, trainNER_userdesc)\n",
    "locXtest_userdesc = NER_text_to_location_features(xtest_text_preprocessed_userdesc, testNER_userdesc)\n",
    "locXval_userdesc = NER_text_to_location_features(xval_text_preprocessed_userdesc, valNER_userdesc)\n",
    "\n",
    "nerXtrain_userdesc =  NER_text_to_features(xtrain_text_preprocessed_userdesc, trainNER_userdesc)\n",
    "nerXtest_userdesc = NER_text_to_features(xtest_text_preprocessed_userdesc, testNER_userdesc)\n",
    "nerXval_userdesc = NER_text_to_features(xval_text_preprocessed_userdesc, valNER_userdesc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3ff201c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T08:24:42.555885Z",
     "start_time": "2022-03-23T08:24:42.459420Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['mentionedLocationUserdesc'] = locXtrain_userdesc\n",
    "test_df['mentionedLocationUserdesc'] = locXtest_userdesc\n",
    "val_df['mentionedLocationUserdesc'] = locXval_userdesc\n",
    "\n",
    "train_df['mentionedEntityUserdesc'] = nerXtrain_userdesc\n",
    "test_df['mentionedEntityUserdesc'] = nerXtest_userdesc\n",
    "val_df['mentionedEntityUserdesc'] = nerXval_userdesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "972c49c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T08:24:46.473790Z",
     "start_time": "2022-03-23T08:24:46.325161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lvalue</th>\n",
       "      <th>isaPerson</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userLocationCode</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>display_name</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_country</th>\n",
       "      <th>pl_place_type</th>\n",
       "      <th>pl_geo_type</th>\n",
       "      <th>pl_geo_bbox</th>\n",
       "      <th>mentionedLocationTweets</th>\n",
       "      <th>mentionedEntityTweets</th>\n",
       "      <th>mentionedLocationDisplayname</th>\n",
       "      <th>mentionedEntityDisplayname</th>\n",
       "      <th>mentionedLocationUserdesc</th>\n",
       "      <th>mentionedEntityUserdesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525235083960321</td>\n",
       "      <td>2021-12-30 12:07:03+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mandiri, Sekuritas.]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mandiri, sekuritas]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525229258133504</td>\n",
       "      <td>2021-12-30 12:07:01+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mandiri, sekuritas]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525223247704068</td>\n",
       "      <td>2021-12-30 12:07:00+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mandiri, sekuritas]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525216951988230</td>\n",
       "      <td>2021-12-30 12:06:58+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mandiri, sekuritas]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525210606063620</td>\n",
       "      <td>2021-12-30 12:06:57+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Mandiri, Sekuritas]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[mandiri, sekuritas]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85329</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460848401692565509</td>\n",
       "      <td>2021-11-17 05:52:54+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85330</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460848330645245957</td>\n",
       "      <td>2021-11-17 05:52:37+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85331</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460846614671618049</td>\n",
       "      <td>2021-11-17 05:45:48+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85332</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460846186408005639</td>\n",
       "      <td>2021-11-17 05:44:06+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nova]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85333</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460845233604730886</td>\n",
       "      <td>2021-11-17 05:40:19+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[nur]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85334 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lvalue  isaPerson  screen_name           userLocation userLocationCode  \\\n",
       "0           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "1           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "2           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "3           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "4           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "...       ...        ...          ...                    ...              ...   \n",
       "85329       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85330       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85331       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85332       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85333       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "\n",
       "                  tweet_id                 created_at   author_id  \\\n",
       "0      1476525235083960321  2021-12-30 12:07:03+00:00   148198201   \n",
       "1      1476525229258133504  2021-12-30 12:07:01+00:00   148198201   \n",
       "2      1476525223247704068  2021-12-30 12:07:00+00:00   148198201   \n",
       "3      1476525216951988230  2021-12-30 12:06:58+00:00   148198201   \n",
       "4      1476525210606063620  2021-12-30 12:06:57+00:00   148198201   \n",
       "...                    ...                        ...         ...   \n",
       "85329  1460848401692565509  2021-11-17 05:52:54+00:00    99895482   \n",
       "85330  1460848330645245957  2021-11-17 05:52:37+00:00    99895482   \n",
       "85331  1460846614671618049  2021-11-17 05:45:48+00:00    99895482   \n",
       "85332  1460846186408005639  2021-11-17 05:44:06+00:00    99895482   \n",
       "85333  1460845233604730886  2021-11-17 05:40:19+00:00    99895482   \n",
       "\n",
       "          username       display_name  ... pl_country pl_place_type  \\\n",
       "0      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "1      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "2      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "3      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "4      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "...            ...                ...  ...        ...           ...   \n",
       "85329       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85330       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85331       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85332       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85333       nurshe      hikari minori  ...        NaN           NaN   \n",
       "\n",
       "      pl_geo_type pl_geo_bbox mentionedLocationTweets  mentionedEntityTweets  \\\n",
       "0             NaN         NaN                      []  [Mandiri, Sekuritas.]   \n",
       "1             NaN         NaN                      []                     []   \n",
       "2             NaN         NaN                      []                     []   \n",
       "3             NaN         NaN                      []                     []   \n",
       "4             NaN         NaN                      []   [Mandiri, Sekuritas]   \n",
       "...           ...         ...                     ...                    ...   \n",
       "85329         NaN         NaN                      []                     []   \n",
       "85330         NaN         NaN                      []                     []   \n",
       "85331         NaN         NaN                      []                     []   \n",
       "85332         NaN         NaN                      []                 [nova]   \n",
       "85333         NaN         NaN                      []                  [nur]   \n",
       "\n",
       "       mentionedLocationDisplayname mentionedEntityDisplayname  \\\n",
       "0                                []       [mandiri, sekuritas]   \n",
       "1                                []       [mandiri, sekuritas]   \n",
       "2                                []       [mandiri, sekuritas]   \n",
       "3                                []       [mandiri, sekuritas]   \n",
       "4                                []       [mandiri, sekuritas]   \n",
       "...                             ...                        ...   \n",
       "85329                            []                         []   \n",
       "85330                            []                         []   \n",
       "85331                            []                         []   \n",
       "85332                            []                         []   \n",
       "85333                            []                         []   \n",
       "\n",
       "      mentionedLocationUserdesc mentionedEntityUserdesc  \n",
       "0                            []                      []  \n",
       "1                            []                      []  \n",
       "2                            []                      []  \n",
       "3                            []                      []  \n",
       "4                            []                      []  \n",
       "...                         ...                     ...  \n",
       "85329                        []                      []  \n",
       "85330                        []                      []  \n",
       "85331                        []                      []  \n",
       "85332                        []                      []  \n",
       "85333                        []                      []  \n",
       "\n",
       "[85334 rows x 28 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dff9969f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T08:27:01.667962Z",
     "start_time": "2022-03-23T08:26:59.807701Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('DataWithNER/train_text.csv')\n",
    "test_df.to_csv('DataWithNER/test_text.csv')\n",
    "val_df.to_csv('DataWithNER/val_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "daf249fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T08:28:43.399144Z",
     "start_time": "2022-03-23T08:28:33.436260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lvalue</th>\n",
       "      <th>isaPerson</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userLocationCode</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>display_name</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_country</th>\n",
       "      <th>pl_place_type</th>\n",
       "      <th>pl_geo_type</th>\n",
       "      <th>pl_geo_bbox</th>\n",
       "      <th>mentionedLocationTweets</th>\n",
       "      <th>mentionedEntityTweets</th>\n",
       "      <th>mentionedLocationDisplayname</th>\n",
       "      <th>mentionedEntityDisplayname</th>\n",
       "      <th>mentionedLocationUserdesc</th>\n",
       "      <th>mentionedEntityUserdesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525235083960321</td>\n",
       "      <td>2021-12-30 12:07:03+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Mandiri Sekuritas.</td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525229258133504</td>\n",
       "      <td>2021-12-30 12:07:01+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525223247704068</td>\n",
       "      <td>2021-12-30 12:07:00+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525216951988230</td>\n",
       "      <td>2021-12-30 12:06:58+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lvalue  isaPerson  screen_name userLocation userLocationCode  \\\n",
       "0       1  nonperson  Mandiri_OLT  jabodetabek              JBD   \n",
       "1       1  nonperson  Mandiri_OLT  jabodetabek              JBD   \n",
       "2       1  nonperson  Mandiri_OLT  jabodetabek              JBD   \n",
       "3       1  nonperson  Mandiri_OLT  jabodetabek              JBD   \n",
       "\n",
       "              tweet_id                 created_at   author_id     username  \\\n",
       "0  1476525235083960321  2021-12-30 12:07:03+00:00   148198201  Mandiri_OLT   \n",
       "1  1476525229258133504  2021-12-30 12:07:01+00:00   148198201  Mandiri_OLT   \n",
       "2  1476525223247704068  2021-12-30 12:07:00+00:00   148198201  Mandiri_OLT   \n",
       "3  1476525216951988230  2021-12-30 12:06:58+00:00   148198201  Mandiri_OLT   \n",
       "\n",
       "        display_name  ... pl_country pl_place_type pl_geo_type pl_geo_bbox  \\\n",
       "0  mandiri sekuritas  ...        NaN           NaN         NaN         NaN   \n",
       "1  mandiri sekuritas  ...        NaN           NaN         NaN         NaN   \n",
       "2  mandiri sekuritas  ...        NaN           NaN         NaN         NaN   \n",
       "3  mandiri sekuritas  ...        NaN           NaN         NaN         NaN   \n",
       "\n",
       "  mentionedLocationTweets mentionedEntityTweets  mentionedLocationDisplayname  \\\n",
       "0                            Mandiri Sekuritas.                                 \n",
       "1                                                                               \n",
       "2                                                                               \n",
       "3                                                                               \n",
       "\n",
       "  mentionedEntityDisplayname mentionedLocationUserdesc mentionedEntityUserdesc  \n",
       "0          mandiri sekuritas                                                    \n",
       "1          mandiri sekuritas                                                    \n",
       "2          mandiri sekuritas                                                    \n",
       "3          mandiri sekuritas                                                    \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "\n",
    "Entitypath = 'DataWithNER'\n",
    "\n",
    "train = pd.read_csv(Entitypath+'/train_text.csv', \n",
    "                    converters={'mentionedLocationTweets': literal_eval, \n",
    "                                'mentionedEntityTweets':literal_eval,\n",
    "                                'mentionedLocationDisplayname':literal_eval,\n",
    "                                'mentionedEntityDisplayname':literal_eval,\n",
    "                                'mentionedLocationUserdesc':literal_eval,\n",
    "                                'mentionedEntityUserdesc':literal_eval,},  \n",
    "                    index_col=[0])\n",
    "\n",
    "test = pd.read_csv(Entitypath+'/test_text.csv', \n",
    "                   converters={'mentionedLocationTweets': literal_eval, \n",
    "                                'mentionedEntityTweets':literal_eval,\n",
    "                                'mentionedLocationDisplayname':literal_eval,\n",
    "                                'mentionedEntityDisplayname':literal_eval,\n",
    "                                'mentionedLocationUserdesc':literal_eval,\n",
    "                                'mentionedEntityUserdesc':literal_eval,}, \n",
    "                   index_col=[0])\n",
    "\n",
    "val = pd.read_csv(Entitypath+'/val_text.csv', \n",
    "                  converters={'mentionedLocationTweets': literal_eval, \n",
    "                                'mentionedEntityTweets':literal_eval,\n",
    "                                'mentionedLocationDisplayname':literal_eval,\n",
    "                                'mentionedEntityDisplayname':literal_eval,\n",
    "                                'mentionedLocationUserdesc':literal_eval,\n",
    "                                'mentionedEntityUserdesc':literal_eval,}, \n",
    "                  index_col=[0])\n",
    "\n",
    "train.mentionedLocationTweets = train.mentionedLocationTweets.apply(lambda x: ' '.join(map(str, x)))\n",
    "test.mentionedLocationTweets = test.mentionedLocationTweets.apply(lambda x: ' '.join(map(str, x)))\n",
    "val.mentionedLocationTweets = val.mentionedLocationTweets.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "train.mentionedEntityTweets = train.mentionedEntityTweets.apply(lambda x: ' '.join(map(str, x)))\n",
    "test.mentionedEntityTweets = test.mentionedEntityTweets.apply(lambda x: ' '.join(map(str, x)))\n",
    "val.mentionedEntityTweets = val.mentionedEntityTweets.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "\n",
    "train.mentionedLocationDisplayname = train.mentionedLocationDisplayname.apply(lambda x: ' '.join(map(str, x)))\n",
    "test.mentionedLocationDisplayname = test.mentionedLocationDisplayname.apply(lambda x: ' '.join(map(str, x)))\n",
    "val.mentionedLocationDisplayname = val.mentionedLocationDisplayname.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "train.mentionedEntityDisplayname = train.mentionedEntityDisplayname.apply(lambda x: ' '.join(map(str, x)))\n",
    "test.mentionedEntityDisplayname = test.mentionedEntityDisplayname.apply(lambda x: ' '.join(map(str, x)))\n",
    "val.mentionedEntityDisplayname = val.mentionedEntityDisplayname.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "train.mentionedLocationUserdesc = train.mentionedLocationUserdesc.apply(lambda x: ' '.join(map(str, x)))\n",
    "test.mentionedLocationUserdesc = test.mentionedLocationUserdesc.apply(lambda x: ' '.join(map(str, x)))\n",
    "val.mentionedLocationUserdesc = val.mentionedLocationUserdesc.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "train.mentionedEntityUserdesc = train.mentionedEntityUserdesc.apply(lambda x: ' '.join(map(str, x)))\n",
    "test.mentionedEntityUserdesc = test.mentionedEntityUserdesc.apply(lambda x: ' '.join(map(str, x)))\n",
    "val.mentionedEntityUserdesc = val.mentionedEntityUserdesc.apply(lambda x: ' '.join(map(str, x)))\n",
    "\n",
    "\n",
    "train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7fef47b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-23T08:29:01.912895Z",
     "start_time": "2022-03-23T08:29:01.813973Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lvalue</th>\n",
       "      <th>isaPerson</th>\n",
       "      <th>screen_name</th>\n",
       "      <th>userLocation</th>\n",
       "      <th>userLocationCode</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>display_name</th>\n",
       "      <th>...</th>\n",
       "      <th>pl_country</th>\n",
       "      <th>pl_place_type</th>\n",
       "      <th>pl_geo_type</th>\n",
       "      <th>pl_geo_bbox</th>\n",
       "      <th>mentionedLocationTweets</th>\n",
       "      <th>mentionedEntityTweets</th>\n",
       "      <th>mentionedLocationDisplayname</th>\n",
       "      <th>mentionedEntityDisplayname</th>\n",
       "      <th>mentionedLocationUserdesc</th>\n",
       "      <th>mentionedEntityUserdesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525235083960321</td>\n",
       "      <td>2021-12-30 12:07:03+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Mandiri Sekuritas.</td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525229258133504</td>\n",
       "      <td>2021-12-30 12:07:01+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525223247704068</td>\n",
       "      <td>2021-12-30 12:07:00+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525216951988230</td>\n",
       "      <td>2021-12-30 12:06:58+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>nonperson</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>jabodetabek</td>\n",
       "      <td>JBD</td>\n",
       "      <td>1476525210606063620</td>\n",
       "      <td>2021-12-30 12:06:57+00:00</td>\n",
       "      <td>148198201</td>\n",
       "      <td>Mandiri_OLT</td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>Mandiri Sekuritas</td>\n",
       "      <td></td>\n",
       "      <td>mandiri sekuritas</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85329</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460848401692565509</td>\n",
       "      <td>2021-11-17 05:52:54+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85330</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460848330645245957</td>\n",
       "      <td>2021-11-17 05:52:37+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85331</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460846614671618049</td>\n",
       "      <td>2021-11-17 05:45:48+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85332</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460846186408005639</td>\n",
       "      <td>2021-11-17 05:44:06+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>nova</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85333</th>\n",
       "      <td>2</td>\n",
       "      <td>person</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>jawa barat dan banten</td>\n",
       "      <td>JB&amp;BT</td>\n",
       "      <td>1460845233604730886</td>\n",
       "      <td>2021-11-17 05:40:19+00:00</td>\n",
       "      <td>99895482</td>\n",
       "      <td>nurshe</td>\n",
       "      <td>hikari minori</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>nur</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85334 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lvalue  isaPerson  screen_name           userLocation userLocationCode  \\\n",
       "0           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "1           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "2           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "3           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "4           1  nonperson  Mandiri_OLT            jabodetabek              JBD   \n",
       "...       ...        ...          ...                    ...              ...   \n",
       "85329       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85330       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85331       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85332       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "85333       2     person       nurshe  jawa barat dan banten            JB&BT   \n",
       "\n",
       "                  tweet_id                 created_at   author_id  \\\n",
       "0      1476525235083960321  2021-12-30 12:07:03+00:00   148198201   \n",
       "1      1476525229258133504  2021-12-30 12:07:01+00:00   148198201   \n",
       "2      1476525223247704068  2021-12-30 12:07:00+00:00   148198201   \n",
       "3      1476525216951988230  2021-12-30 12:06:58+00:00   148198201   \n",
       "4      1476525210606063620  2021-12-30 12:06:57+00:00   148198201   \n",
       "...                    ...                        ...         ...   \n",
       "85329  1460848401692565509  2021-11-17 05:52:54+00:00    99895482   \n",
       "85330  1460848330645245957  2021-11-17 05:52:37+00:00    99895482   \n",
       "85331  1460846614671618049  2021-11-17 05:45:48+00:00    99895482   \n",
       "85332  1460846186408005639  2021-11-17 05:44:06+00:00    99895482   \n",
       "85333  1460845233604730886  2021-11-17 05:40:19+00:00    99895482   \n",
       "\n",
       "          username       display_name  ... pl_country pl_place_type  \\\n",
       "0      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "1      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "2      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "3      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "4      Mandiri_OLT  mandiri sekuritas  ...        NaN           NaN   \n",
       "...            ...                ...  ...        ...           ...   \n",
       "85329       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85330       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85331       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85332       nurshe      hikari minori  ...        NaN           NaN   \n",
       "85333       nurshe      hikari minori  ...        NaN           NaN   \n",
       "\n",
       "      pl_geo_type pl_geo_bbox mentionedLocationTweets mentionedEntityTweets  \\\n",
       "0             NaN         NaN                            Mandiri Sekuritas.   \n",
       "1             NaN         NaN                                                 \n",
       "2             NaN         NaN                                                 \n",
       "3             NaN         NaN                                                 \n",
       "4             NaN         NaN                             Mandiri Sekuritas   \n",
       "...           ...         ...                     ...                   ...   \n",
       "85329         NaN         NaN                                                 \n",
       "85330         NaN         NaN                                                 \n",
       "85331         NaN         NaN                                                 \n",
       "85332         NaN         NaN                                          nova   \n",
       "85333         NaN         NaN                                           nur   \n",
       "\n",
       "       mentionedLocationDisplayname mentionedEntityDisplayname  \\\n",
       "0                                            mandiri sekuritas   \n",
       "1                                            mandiri sekuritas   \n",
       "2                                            mandiri sekuritas   \n",
       "3                                            mandiri sekuritas   \n",
       "4                                            mandiri sekuritas   \n",
       "...                             ...                        ...   \n",
       "85329                                                            \n",
       "85330                                                            \n",
       "85331                                                            \n",
       "85332                                                            \n",
       "85333                                                            \n",
       "\n",
       "      mentionedLocationUserdesc mentionedEntityUserdesc  \n",
       "0                                                        \n",
       "1                                                        \n",
       "2                                                        \n",
       "3                                                        \n",
       "4                                                        \n",
       "...                         ...                     ...  \n",
       "85329                                                    \n",
       "85330                                                    \n",
       "85331                                                    \n",
       "85332                                                    \n",
       "85333                                                    \n",
       "\n",
       "[85334 rows x 28 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0923d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
